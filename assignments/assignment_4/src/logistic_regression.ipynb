{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier benchmarks using Logistic Regression and a Neural Network\n",
    "\n",
    "\n",
    "\n",
    "This assignment builds on the work we did in class and from session 6.\n",
    "\n",
    "\n",
    "\n",
    "You'll use your new knowledge and skills to create two command-line tools which can be used to perform a simple classification task on the MNIST data and print the output to the terminal. These scripts can then be used to provide easy-to-understand benchmark scores for evaluating these models.\n",
    "\n",
    "\n",
    "\n",
    "You should create two Python scripts. One takes the full MNIST data set, trains a Logistic Regression Classifier, and prints the evaluation metrics to the terminal. The other should take the full MNIST dataset, train a neural network classifier, and print the evaluation metrics to the terminal.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Tips\n",
    "\n",
    "I suggest using scikit-learn for the Logistic Regression Classifier\n",
    "In class, we only looked at a small sample of MNIST data. I suggest using fetch_openml() to get the full dataset, like we did in session 6\n",
    "You can use the NeuralNetwork() class that I introduced you to during the code along session\n",
    "I recommend saving your .py scripts in a folder called srcï»¿; and have your NeuralNetwork class in a folder called utils, like we have on worker02\n",
    "You may need to do some data manipulation to get the MNIST data into a usable format for your models\n",
    "If you have trouble doing this on your own machine, use worker02!\n",
    "\n",
    "\n",
    "Bonus Challenges\n",
    "\n",
    "Have the scripts save the classifier reports in a folder called out, as well as printing them to screen. Add The user should be able to define the file name as a command line argument (easier)\n",
    "Allow users to define the number and size of the hidden layers using command line arguments (intermediate)\n",
    "Allow the user to define Logistic Regression parameters using command line arguments (intermediate)\n",
    "Add an additional step where you import some unseen image, process it, and use the trained model to predict it's value - like we did in session 6 (intermediate)\n",
    "Add a new method to the Neural Network class which will allow you to save your trained model for future use (advanced)\n",
    "\n",
    "\n",
    "General instructions\n",
    "\n",
    "Save your script as lr-mnist.py and nn-mnist.py\n",
    "If you have external dependencies, you must include a requirements.txt\n",
    "You can either upload the script here or push to GitHub and include a link - or both!\n",
    "Your code should be clearly documented in a way that allows others to easily follow along\n",
    "Similarly, remember to use descriptive variable names! A name like X_train is (just) more readable than x1.\n",
    "The filenames of the saved images should clearly relate to the original image\n",
    "\n",
    "\n",
    "Purpose\n",
    "\n",
    "This assignment is designed to test that you have a understanding of:\n",
    "\n",
    "how to train classification models using machine learning and neural networks;\n",
    "how to create simple models that can be used as statistical benchmarks;\n",
    "how to do this using scripts which can be executed from the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path tools\n",
    "import sys,os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import utils.classifier_utils as clf_util\n",
    "#neural networks with numpy\n",
    "from utils.neuralnetwork import NeuralNetwork\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify categories\n",
    "classes = sorted(set(y)) # The names of each class (0-9)\n",
    "nclasses = len(classes) #number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # our data\n",
    "                                                    y, # our labels\n",
    "                                                    #random_state=9,\n",
    "                                                    train_size=7500, \n",
    "                                                    test_size=2500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the features \n",
    "#scaling the features\n",
    "X_train_scaled = X_train/255.0\n",
    "X_test_scaled = X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a logistic regression model\n",
    "clf = LogisticRegression(penalty='none', \n",
    "                         tol=0.1, \n",
    "                         solver='saga',\n",
    "                         multi_class='multinomial').fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to check the shape of the coefficient matrix\n",
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict test data\n",
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       234\n",
      "           1       0.93      0.96      0.95       278\n",
      "           2       0.90      0.90      0.90       267\n",
      "           3       0.89      0.89      0.89       261\n",
      "           4       0.90      0.90      0.90       232\n",
      "           5       0.88      0.86      0.87       224\n",
      "           6       0.91      0.94      0.92       257\n",
      "           7       0.91      0.95      0.93       248\n",
      "           8       0.89      0.83      0.86       243\n",
      "           9       0.90      0.88      0.89       256\n",
      "\n",
      "    accuracy                           0.91      2500\n",
      "   macro avg       0.91      0.90      0.91      2500\n",
      "weighted avg       0.91      0.91      0.91      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.classification_report(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_environment",
   "language": "python",
   "name": "sentiment_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
